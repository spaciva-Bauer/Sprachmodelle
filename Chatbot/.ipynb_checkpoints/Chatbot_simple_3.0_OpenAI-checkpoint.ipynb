{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d02657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wird nur bei der ersten Ausführung benötigt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "961d9759",
   "metadata": {},
   "source": [
    "pip install openai "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ca636",
   "metadata": {},
   "source": [
    "# Einfacher Python-Client für einen Chat-Assistenten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44b184",
   "metadata": {},
   "source": [
    "### Die Firma OpenAI bietet ein Python-Modul an, welches alle notwendigen Funktionen enthält, um mit einem Sprachmodell zu kommunizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31624afc",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdf8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mein_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "max_tokens = 100\n",
    "kreatititaet = 0 # Werte zwischen 0 und 2 sind möglich; 2 ist maximale Kreativitaet der Antwort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99dfac",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7cf2d",
   "metadata": {},
   "source": [
    "## 1. Formuliere die erste Anfrage an das System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471afaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "systempromt = \"Du bist ein Chatbot. Antworte immer total genervt und trotzig.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569eed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "userprompt1 = \"Weißt Du wer ich bin?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages1 = [\n",
    "    {\"role\": \"system\", \"content\": systempromt},\n",
    "    {\"role\": \"user\", \"content\": userprompt1},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca1f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "antwort1 = mein_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=messages1, max_output_tokens=max_tokens, temperature=kreatititaet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(antwort1.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099403aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(antwort1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ff448",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8ff20",
   "metadata": {},
   "source": [
    "## 2. Stelle dem System eine weitere Frage mit Bezug zur ersten Antwort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "userprompt2=\"Sei nicht so garstig!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2 = [\n",
    "    {\"role\": \"system\", \"content\": systempromt},\n",
    "    {\"role\": \"user\", \"content\": userprompt1},\n",
    "    {\"role\": \"assistant\", \"content\": antwort1.output[0].content[0].text},\n",
    "    {\"role\": \"user\", \"content\": userprompt2},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ebbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "antwort2 = mein_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=messages2, max_output_tokens=max_tokens, temperature=kreatititaet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30787a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(antwort2.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(antwort2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcfb76a",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273a459",
   "metadata": {},
   "source": [
    "## 3. beliebig lange Frage-Antwort-Sequenz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a91cda1",
   "metadata": {},
   "source": [
    "Das folgende Beispiel zeigt, wie nach den Fragen 1 und 2 ein Chat-Verlauf weiter geführt werden könnte. Dies kennt man i. A. von Webseiten, die Chat-Bots anbieten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatverlauf = []\n",
    "chatverlauf.append({\"role\": \"system\", \"content\": systempromt})\n",
    "chatverlauf.append({\"role\": \"user\", \"content\": userprompt1})                                \n",
    "chatverlauf.append({\"role\": \"assistant\", \"content\": antwort1.output[0].content[0].text})\n",
    "chatverlauf.append({\"role\": \"user\", \"content\": userprompt2})\n",
    "chatverlauf.append({\"role\": \"assistant\", \"content\": antwort2.output[0].content[0].text})\n",
    "\n",
    "neue_usereingabe = \"\"\n",
    "antwort_neu = \"\"   \n",
    "\n",
    "while neue_usereingabe != \"exit\":\n",
    "    neue_usereingabe = input()\n",
    "    if neue_usereingabe!= \"exit\":\n",
    "        neue_Nachricht = chatverlauf.append({\"role\": \"user\", \"content\": neue_usereingabe}) \n",
    "        antwort_neu = mein_client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=chatverlauf, max_output_tokens=max_tokens, temperature=kreatititaet)\n",
    "        print(antwort_neu.output[0].content[0].text)\n",
    "        chatverlauf.append({\"role\": \"assistant\", \"content\": antwort_neu.output[0].content[0].text})             \n",
    "                 \n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8101250",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chatverlauf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(antwort_neu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383675f1",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f59536",
   "metadata": {},
   "source": [
    "## 4. Aufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a743b8",
   "metadata": {},
   "source": [
    "* Experimentieren Sie mit der Systemantwort.\n",
    "  \n",
    "  Der Chatbot soll...\n",
    "   * höflich antworten\n",
    "   * jede Antwort in eine bestimmte Sprache übersetzen\n",
    "   * wie ein Pirat sprechen\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77a114",
   "metadata": {},
   "source": [
    "* Experimentieren Sie mit dem Wert der **Kreativität** (Temperatur). Beschreiben Sie die Auswirkung der gewählten Niveaustufen von 0 - 2 in Bezug auf die Antwort des Systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f567c7",
   "metadata": {},
   "source": [
    "* Die maximal ausgegebene Anzahl von Tokens einer Antwort kann dem System auch über einen Prompt vorgegeben werden. Beschreiben Sie den Vorteil der hier verwendeten Methode (Verwendung des Parameters max_output_tokens). Finden Sie den minimalen Wert, den das System akzeptiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e63f2",
   "metadata": {},
   "source": [
    "* Finden Sie mit Hife von 1. und 2. heraus, unter welchen Voraussetzungen sich das Sprachmodell an Details der Konversation \"erinnern\" kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ccac5",
   "metadata": {},
   "source": [
    "* Ändern Sie den Code unter 3. so ab, dass eine völlig neue Konversation (ohne den Bezug zu den ersten beiden Anfragen sowie den zugehörigen Antworten) geführt werden kann. Erhalten Sie aber den Systemprompt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
