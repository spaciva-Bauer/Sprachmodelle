{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d02657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wird nur bei der ersten Ausführung benötigt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "961d9759",
   "metadata": {},
   "source": [
    "pip install openai "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ca636",
   "metadata": {},
   "source": [
    "# Einfacher Python-Client für einen Chat-Assistenten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44b184",
   "metadata": {},
   "source": [
    "### Die Firma OpenAI bietet ein Python-Modul an, welches alle notwendigen Funktionen enthält, um mit einem Sprachmodell Kontakt aufzunehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d39ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31624afc",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdf8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mein_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "max_tokens = 100\n",
    "kreatititaet = 0 # Werte zwischen 0 und 2 sind möglich; 2 ist maximale Kreativitaet der Antwort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99dfac",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7cf2d",
   "metadata": {},
   "source": [
    "## 1. Formuliere die erste Anfrage an das System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471afaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "systempromt = \"Du bist ein Chatbot. Antworte immer total genervt und trotzig.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569eed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "userprompt1 = \"Weißt Du wer ich bin?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages1 = [\n",
    "    {\"role\": \"system\", \"content\": systempromt},\n",
    "    {\"role\": \"user\", \"content\": userprompt1},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca1f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "antwort1 = mein_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=messages1, max_output_tokens=max_tokens, temperature=kreatititaet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(antwort1.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ff448",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8ff20",
   "metadata": {},
   "source": [
    "## 2. Stelle dem System eine weitere Frage mit Bezug zur ersten Antwort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "userprompt2=\"Sei nicht so garstig!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2 = [\n",
    "    {\"role\": \"system\", \"content\": systempromt},\n",
    "    {\"role\": \"user\", \"content\": userprompt1},\n",
    "    {\"role\": \"assistant\", \"content\": antwort1.output[0].content[0].text},\n",
    "    {\"role\": \"user\", \"content\": userprompt2},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ebbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "antwort2 = mein_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=messages2, max_output_tokens=max_tokens, temperature=kreatititaet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30787a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(antwort2.output[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcfb76a",
   "metadata": {},
   "source": [
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f59536",
   "metadata": {},
   "source": [
    "## 3. Aufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a743b8",
   "metadata": {},
   "source": [
    "* Experimentiere mit der Systemantwort.\n",
    "  \n",
    "  Der Chatbot soll...\n",
    "   * höflich antworten\n",
    "   * jede Antwort ins Spanische übersetzen\n",
    "   * wie ein Pirat sprechen\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e63f2",
   "metadata": {},
   "source": [
    "* Erweitere den Code so, dass eine dritte Frage-Antwort-Sequenz entsteht."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77a114",
   "metadata": {},
   "source": [
    "* Experimentiere mit dem Wert der **Kreativität**. Beschreibe die Auswirkung der gewählten Niveaustufen von 0 - 2 in Bezug auf die Antwort des Systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f567c7",
   "metadata": {},
   "source": [
    "* Die maximal ausgegebene Anzahl von Tokens einer Antwort kann dem System auch über einen Prompt vorgegeben werden. Beschreibe den Vorteil der hier verwendeten Methode (Verwendung des Parameters max_output_tokens). Finde den minimalen Wert, den das System akzeptiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273a459",
   "metadata": {},
   "source": [
    "## Frage-Antwort-Sequenz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a91cda1",
   "metadata": {},
   "source": [
    "Das folgende Beispiel zeigt, wie nach den Fragen 1 und 2 ein Chat-Verlauf weiter geführt werden könnte. Dies kennt man i.A. von Webseiten, die Chat-Bots anbieten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatverlauf = []\n",
    "chatverlauf.append({\"role\": \"system\", \"content\": systempromt})\n",
    "chatverlauf.append({\"role\": \"user\", \"content\": userprompt1})                                \n",
    "chatverlauf.append({\"role\": \"assistant\", \"content\": antwort1.output[0].content[0].text})\n",
    "chatverlauf.append({\"role\": \"user\", \"content\": userprompt2})\n",
    "chatverlauf.append({\"role\": \"assistant\", \"content\": antwort2.output[0].content[0].text})\n",
    "\n",
    "neue_usereingabe =\"\"\n",
    "                 \n",
    "while neue_usereingabe != \"exit\":\n",
    "    neue_usereingabe = input()\n",
    "    neue_Nachricht = chatverlauf.append({\"role\": \"user\", \"content\": neue_usereingabe}) \n",
    "    antwort_neu = mein_client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=chatverlauf, max_output_tokens=max_tokens, temperature=kreatititaet)\n",
    "    print(antwort_neu.output[0].content[0].text)\n",
    "    chatverlauf.append({\"role\": \"assistant\", \"content\": antwort_neu.output[0].content[0].text})             \n",
    "                 \n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8101250",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chatverlauf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
